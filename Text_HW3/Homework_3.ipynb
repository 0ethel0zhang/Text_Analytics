{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from collections import Counter\n",
    "#import pickle\n",
    "#from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a WordNetLemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read lines as lists\n",
    "lines_each = []\n",
    "with open(\"ratemd.25k.all.txt\", \"r\") as f:\n",
    "    lines_each.append(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task#1: Corpus collection and Corpus Descriptive analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem#1:\n",
    "Do a descriptive analysis of your corpus and provide (in the table below): the distribution of reviews per gender and sentiment (show both count and percent coverage). \n",
    "\n",
    "Here the sentiment can be only positive or negative -- determined by mapping the overall ratings of at most 3 into negative (i.e., [1,3]) and those at least 4 into positive (i.e., [4,5]). E.g., the overall rating of the example above maps into positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create English stop words list (you can always define your own stopwords)\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to remove stop words from sentences & lemmatize verbs and nouns. \n",
    "def clean(doc, lem = True):\n",
    "    tokenized = word_tokenize(doc.lower())\n",
    "    stop_free = [x for x in tokenized if not re.fullmatch('[' + string.punctuation + ']+', x) and x not in stop_words]\n",
    "    if lem:\n",
    "        lemma_verb = [lemmatizer.lemmatize(word,'v') for word in stop_free]\n",
    "        lemma_noun = [lemmatizer.lemmatize(word,'n') for word in lemma_verb]\n",
    "        #y = [s for s in lemma_noun if len(s) > 2]\n",
    "        return lemma_noun\n",
    "    else:\n",
    "        return stop_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_lower = [x.lower() for x in lines_each[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_name = re.compile(r\"dr.\\s\\w*\\s\\w*[.]?\\s?\\w*\\s\\w*\\s?\\t\\s[a-z]{0,2}male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender = {}\n",
    "rating = {}\n",
    "doc = 0\n",
    "for x in lines_lower:\n",
    "    m = re.search(doc_name, x)\n",
    "    if m:\n",
    "        doc += 1 #=x[:m.end()-4]\n",
    "    search = re.findall(r'(male|female)', x)\n",
    "    if len(search) > 0:\n",
    "        gender[doc] = search[0]\n",
    "    match = re.search('overall rating:\\s\\d.\\d+', x)\n",
    "    if match:\n",
    "        if match.end() > 19:\n",
    "            new = x[match.end()-4:match.end()]\n",
    "        else:\n",
    "            new = x[match.end()-3:match.end()]\n",
    "        try:\n",
    "            old = rating[doc]\n",
    "            rep = old + \"\\s\" + new\n",
    "            rating[doc] = rep\n",
    "        except:\n",
    "            rating[doc] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are doctors without ratings\n",
    "dif = list(set(gender.keys()) - set(rating.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_rating = []\n",
    "m_rating = []\n",
    "m = 0\n",
    "f = 0\n",
    "\n",
    "for k, v in gender.items():\n",
    "    if k not in dif:\n",
    "        score = rating[k].split(r\"\\s\")\n",
    "        for s in score:\n",
    "            if v == \"male\":\n",
    "                m_rating.append(float(s))\n",
    "                m += 1\n",
    "            else:\n",
    "                f_rating.append(float(s))\n",
    "                f += 1\n",
    "    else:\n",
    "        if v == \"male\":\n",
    "            m_rating.append(None)\n",
    "            m += 1\n",
    "        else:\n",
    "            f_rating.append(None)\n",
    "            f += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_p = 0\n",
    "f_n = 0\n",
    "for x in f_rating:\n",
    "    if x:\n",
    "        if x >= 4:\n",
    "            f_p += 1\n",
    "        elif x>= 0:\n",
    "            f_n += 1\n",
    "m_p = 0\n",
    "m_n = 0\n",
    "for x in m_rating:\n",
    "    if x:\n",
    "        if x >= 4:\n",
    "            m_p += 1\n",
    "        elif x>= 0:\n",
    "            m_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl = (f_p, f_n, f_p/len(f_rating)*100, \n",
    "       f_n/len(f_rating)*100,len(f_rating),\n",
    "       len(f_rating)/(m+f)*100,\n",
    "       m_p, m_n, \n",
    "       m_p/len(m_rating)*100, \n",
    "       m_n/len(m_rating)*100,\n",
    "       len(m_rating),\n",
    "       len(m_rating)/(m+f)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P1_tbl = pd.DataFrame(np.array(np.reshape(tbl, (2,6))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give table index and column\n",
    "P1_tbl.columns = [\"Positive_cnt\", \"Negative_cnt\",\n",
    "                 \"Positive_%\", \"Negative_%\",\"Total_cnt\", \n",
    "                  \"Total_%\"]\n",
    "P1_tbl['Gender'] = ['Female', 'Male']\n",
    "P1_tbl = P1_tbl.set_index(\"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_cnt</th>\n",
       "      <th>Negative_cnt</th>\n",
       "      <th>Positive_%</th>\n",
       "      <th>Negative_%</th>\n",
       "      <th>Total_cnt</th>\n",
       "      <th>Total_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>3030.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>56.372093</td>\n",
       "      <td>42.102326</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>25.88241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>9532.0</td>\n",
       "      <td>5595.0</td>\n",
       "      <td>61.928274</td>\n",
       "      <td>36.350052</td>\n",
       "      <td>15392.0</td>\n",
       "      <td>74.11759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Positive_cnt  Negative_cnt  Positive_%  Negative_%  Total_cnt  \\\n",
       "Gender                                                                  \n",
       "Female        3030.0        2263.0   56.372093   42.102326     5375.0   \n",
       "Male          9532.0        5595.0   61.928274   36.350052    15392.0   \n",
       "\n",
       "         Total_%  \n",
       "Gender            \n",
       "Female  25.88241  \n",
       "Male    74.11759  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'w+') as f:\n",
    "    f.writelines(\"\\nTask 1 Problem 1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P1_tbl.to_csv(r'analysis.txt', sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also provide and comment on the size of the reviews in the corpus: i.e., the length of the smallest review and of the largest review, as well as the average length of the reviews in the corpus. \n",
    "\n",
    "Here the length of a review is defined as the number of raw tokens (i.e., any sequence of characters separated by space and/or beginning/end of review)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = []\n",
    "for x in lines_lower:\n",
    "    match = re.search(r'overall rating:\\s\\d.\\d+\\s\\t\\s', x)\n",
    "    if match:\n",
    "        review.append(x[match.end():-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "for x in lines_lower:\n",
    "    match = re.search(r'overall rating:\\s\\d.\\d+\\s\\t\\s', x)\n",
    "    if match:\n",
    "        if match.end() > 22:\n",
    "            score.append(float(x[match.end()-7:match.end()-3]))\n",
    "        else:\n",
    "            score.append(float(x[match.end()-6:match.end()-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws_tokenize = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok_review = []\n",
    "for r in review:\n",
    "    if len(ws_tokenize.tokenize(r)) > 0:\n",
    "        tok_review.append(len(ws_tokenize.tokenize(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P2_tbl = pd.DataFrame(tok_review).describe().T[['min','mean', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>65.360652</td>\n",
       "      <td>899.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min       mean    max\n",
       "0  1.0  65.360652  899.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines(\"\\nTask 1 Problem 1 EDA\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P2_tbl.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem#2:\n",
    "Why is this dataset from RateMD a valid, relevant corpus for your project?\n",
    "\n",
    "For this, you are referred to the corpus design principles discussed in class (Lecture 5). \n",
    "\n",
    "In particular, consider the following helping questions and fill in the entries in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20420.0</td>\n",
       "      <td>3.741467</td>\n",
       "      <td>1.480644</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      mean       std   min   25%  50%  75%  max\n",
       "0  20420.0  3.741467  1.480644  0.75  2.25  4.5  5.0  5.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P12_tbl = pd.DataFrame(score).describe().T\n",
    "P12_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P22_tbl = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P22_tbl['Questions'] = ['What is the language variety of the corpus (i.e., genre)?',\n",
    "'What is the size of the corpus?',\n",
    "'What meta-data is provided with the reviews?',\n",
    "'What socio-demographic information is provided about the patients who wrote the reviews?',\n",
    "'Is the corpus balanced along the meta-data dimensions considered? (look only at sentiment and gender)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P22_tbl['RateMD corpus'] = ['Reviews written by anyone who has access to the internet',\n",
    "'19,645 non-empty reviews',\n",
    "'Doctor’s name, gender, clinic location, specialty, rating, review',\n",
    "'Nothing',\n",
    "'No. 1) There are significantly more male doctors being reviewed. 2) The ratings are not uniform. There are significantly more score 5 reviews (see table below).']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P22_tbl['Healthcare company’s corpus'] =['Reviews written by patients of the company’s clinics',\n",
    "'500,000 reviews',\n",
    "'Doctor’s name, gender, clinic location; review sentiment',\n",
    "'Gender, age, economic and educational status',\n",
    "'No (the dimensions are not uniformly distributed; they exhibit a natural distribution)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines(\"\\nTask 1 Problem 2\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P22_tbl.to_csv(r'analysis.txt', sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P12_tbl.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task#2: Exploratory Analysis of Corpus with LDA\n",
    "\n",
    "You have to write a python program that takes as input the corpus (i.e., your RateMD corpus), a given number of topics k, and generates these topics. For this task you will experiment with LDA (Latent Dirichlet Allocation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clean the corpus\n",
    "First, by looking at the stats you got on the corpus in Problem1, you realize that some comments are empty or contain just one word. Thus, here are some possible cleaning procedures you might want to do:\n",
    "\n",
    "- convert the text reviews to lowercase \n",
    "- remove reviews with less than 3 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long_review = [x for x in review if len(x) > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tokenize them \n",
    "- remove punctuations, and stop words.\n",
    "- You also decide to filter the terms which occurred less than 10 times in your documents (i.e., reviews).\n",
    "- with and without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with lemmatization\n",
    "skim_review = [clean(doc.strip()) for doc in long_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# without lemmatization\n",
    "ori_review = [clean(doc.strip(), False) for doc in long_review]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the dictionary\n",
    "After you cleaned your corpus, you will create the term dictionary. How large is your dictionary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = [(k,v) for k,v in Counter([item for sublist in skim_review for item in sublist]).items() \n",
    "        if v >= 10 and re.search('\\d+', k) is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = [x[0] for x in freq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ori_freq = [(k,v) for k,v in Counter([item for sublist in ori_review for item in sublist]).items() \n",
    "            if v >= 10 and re.search('\\d+', k) is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ori_dictionary = [x[0] for x in ori_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writeline('\\nTask 2\\n')\n",
    "    f.writelines('Length of dictionary without lemmatization is {}.\\n'.format(len(ori_dictionary)))\n",
    "    f.writelines('Length of dictionary with lemmatization is {}.\\n'.format(len(dictionary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: \n",
    "Convert the list of documents in your corpus into Document-Term Matrix using the dictionary prepared at Step 2 (again, a term is a word)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dic = corpora.Dictionary([dictionary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [Dic.doc2bow(doc_clean) for doc_clean in skim_review]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ori_Dic = corpora.Dictionary([ori_dictionary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ori_corpus = [Dic.doc2bow(doc_clean) for doc_clean in ori_review]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the LDA model on the document-term matrix\n",
    "\n",
    "Here you have to run LDA with the following parameters: number of topics (k = 10), number of passes (pass = 20), and number of iterations (iterations = 2000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA model needs many iterations/passes and a large corpus to work well\n",
    "# must define the number of topics you want to extract from the corpus\n",
    "ldamodel = LdaModel(corpus, num_topics=10, id2word = Dic, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA model needs many iterations/passes and a large corpus to work well\n",
    "# must define the number of topics you want to extract from the corpus\n",
    "ori_ldamodel = LdaModel(ori_corpus, num_topics=10, id2word = ori_Dic, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: For each of the k topics, print the top 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem#1: Without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print out the top 10 words in each topic\n",
    "ori_tops = ori_ldamodel.print_topics(num_topics=10, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_21_ori = pd.DataFrame([re.findall(\"\\\"\\w*[.']?\\w*\\\"\", x[1]) for x in ori_tops[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_21_ori['topic'] = ['Specific Cases', 'Professional Doctors', 'Thorough Treatment', 'Lecturing Doctors', 'Bad Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"baldwin\"</td>\n",
       "      <td>\"dipatri\"</td>\n",
       "      <td>\"complaint\"</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>\"bye\"</td>\n",
       "      <td>\"dascombe\"</td>\n",
       "      <td>\"exam\"</td>\n",
       "      <td>Specific Cases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"nami\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"precious\"</td>\n",
       "      <td>\"discovered\"</td>\n",
       "      <td>\"figured\"</td>\n",
       "      <td>\"imagine\"</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>\"hateful\"</td>\n",
       "      <td>Professional Doctors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"glazer\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"individual\"</td>\n",
       "      <td>\"loewe\"</td>\n",
       "      <td>\"bothered\"</td>\n",
       "      <td>\"father\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"main\"</td>\n",
       "      <td>\"cheap\"</td>\n",
       "      <td>\"induction\"</td>\n",
       "      <td>Thorough Treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"bonakdar\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"refreshing\"</td>\n",
       "      <td>\"physican\"</td>\n",
       "      <td>\"home\"</td>\n",
       "      <td>\"ford\"</td>\n",
       "      <td>\"biopsy\"</td>\n",
       "      <td>\"professional\"</td>\n",
       "      <td>\"reply\"</td>\n",
       "      <td>\"contacted\"</td>\n",
       "      <td>Lecturing Doctors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"jensen\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"everyone\"</td>\n",
       "      <td>\"kent\"</td>\n",
       "      <td>\"honor\"</td>\n",
       "      <td>\"ethics\"</td>\n",
       "      <td>\"diligent\"</td>\n",
       "      <td>\"closely\"</td>\n",
       "      <td>\"paralyzed\"</td>\n",
       "      <td>Bad Experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1             2           3           4             5  \\\n",
       "0       \"cut\"  \"data\"          \"'s\"   \"baldwin\"   \"dipatri\"   \"complaint\"   \n",
       "1      \"nami\"  \"data\"         \"cut\"   \"service\"  \"precious\"  \"discovered\"   \n",
       "2    \"glazer\"  \"data\"  \"individual\"     \"loewe\"  \"bothered\"      \"father\"   \n",
       "3  \"bonakdar\"  \"data\"  \"refreshing\"  \"physican\"      \"home\"        \"ford\"   \n",
       "4    \"jensen\"   \"cut\"     \"service\"  \"everyone\"      \"kent\"       \"honor\"   \n",
       "\n",
       "            6               7           8            9                 topic  \n",
       "0  \"expected\"           \"bye\"  \"dascombe\"       \"exam\"        Specific Cases  \n",
       "1   \"figured\"       \"imagine\"  \"expected\"    \"hateful\"  Professional Doctors  \n",
       "2        \"'s\"          \"main\"     \"cheap\"  \"induction\"    Thorough Treatment  \n",
       "3    \"biopsy\"  \"professional\"     \"reply\"  \"contacted\"     Lecturing Doctors  \n",
       "4    \"ethics\"      \"diligent\"   \"closely\"  \"paralyzed\"        Bad Experience  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_21_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_22_ori = pd.DataFrame([re.findall(\"\\\"\\w*[.']?\\w*\\\"\", x[1]) for x in ori_tops[5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_22_ori['topic'] = ['Neutral Visit', 'Retired Patient?', 'Emotional Visit?', 'Not Great Experience', 'Saturday Light-Hearted Visits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"laptop\"</td>\n",
       "      <td>\"precious\"</td>\n",
       "      <td>\"redo\"</td>\n",
       "      <td>\"sarcastic\"</td>\n",
       "      <td>\"anterior\"</td>\n",
       "      <td>\"ethics\"</td>\n",
       "      <td>\"blown\"</td>\n",
       "      <td>\"paralyzed\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>Neutral Visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"relaxed\"</td>\n",
       "      <td>\"seeing\"</td>\n",
       "      <td>\"lazy\"</td>\n",
       "      <td>\"mexico\"</td>\n",
       "      <td>\"overall\"</td>\n",
       "      <td>\"dascombe\"</td>\n",
       "      <td>\"knowing\"</td>\n",
       "      <td>\"panchal\"</td>\n",
       "      <td>\"hemorrhoids\"</td>\n",
       "      <td>Retired Patient?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"redo\"</td>\n",
       "      <td>\"alcohol\"</td>\n",
       "      <td>\"drink\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"precious\"</td>\n",
       "      <td>\"honor\"</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>\"much\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>Emotional Visit?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"pulmonary\"</td>\n",
       "      <td>\"mian\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"pulling\"</td>\n",
       "      <td>\"nami\"</td>\n",
       "      <td>\"easier\"</td>\n",
       "      <td>\"medicine\"</td>\n",
       "      <td>\"dislike\"</td>\n",
       "      <td>\"associated\"</td>\n",
       "      <td>Not Great Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"likely\"</td>\n",
       "      <td>\"pulmonary\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"associates\"</td>\n",
       "      <td>\"dascombe\"</td>\n",
       "      <td>\"home\"</td>\n",
       "      <td>\"realized\"</td>\n",
       "      <td>\"closely\"</td>\n",
       "      <td>\"everytime\"</td>\n",
       "      <td>\"hart\"</td>\n",
       "      <td>Saturday Light-Hearted Visits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0            1          2             3           4           5  \\\n",
       "0  \"laptop\"   \"precious\"     \"redo\"   \"sarcastic\"  \"anterior\"    \"ethics\"   \n",
       "1    \"data\"    \"relaxed\"   \"seeing\"        \"lazy\"    \"mexico\"   \"overall\"   \n",
       "2    \"data\"       \"redo\"  \"alcohol\"       \"drink\"       \"cut\"  \"precious\"   \n",
       "3    \"data\"  \"pulmonary\"     \"mian\"     \"service\"   \"pulling\"      \"nami\"   \n",
       "4  \"likely\"  \"pulmonary\"     \"data\"  \"associates\"  \"dascombe\"      \"home\"   \n",
       "\n",
       "            6            7            8              9  \\\n",
       "0     \"blown\"  \"paralyzed\"       \"data\"          \"cut\"   \n",
       "1  \"dascombe\"    \"knowing\"    \"panchal\"  \"hemorrhoids\"   \n",
       "2     \"honor\"   \"expected\"       \"much\"           \"'s\"   \n",
       "3    \"easier\"   \"medicine\"    \"dislike\"   \"associated\"   \n",
       "4  \"realized\"    \"closely\"  \"everytime\"         \"hart\"   \n",
       "\n",
       "                           topic  \n",
       "0                  Neutral Visit  \n",
       "1               Retired Patient?  \n",
       "2               Emotional Visit?  \n",
       "3           Not Great Experience  \n",
       "4  Saturday Light-Hearted Visits  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_22_ori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All of the topics without lemmatization looks confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem#2: With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print out the top 10 words in each topic\n",
    "tops = ldamodel.print_topics(num_topics=10, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_21 = pd.DataFrame([re.findall(\"\\\"\\w*[.']?\\w*\\\"\", x[1]) for x in tops[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_21['topic'] = ['Bad Experience', 'High Cost', 'Baby Delivery Doctor', 'Great Review', 'Long Wait Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"staff\"</td>\n",
       "      <td>\"care\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"recommend\"</td>\n",
       "      <td>\"great\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>\"knowledgeable\"</td>\n",
       "      <td>\"highly\"</td>\n",
       "      <td>\"patient\"</td>\n",
       "      <td>Bad Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"surgery\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"procedure\"</td>\n",
       "      <td>\"surgeon\"</td>\n",
       "      <td>\"result\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>\"recommend\"</td>\n",
       "      <td>\"perform\"</td>\n",
       "      <td>\"go\"</td>\n",
       "      <td>\"breast\"</td>\n",
       "      <td>High Cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"manner\"</td>\n",
       "      <td>\"bedside\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"good\"</td>\n",
       "      <td>\"great\"</td>\n",
       "      <td>\"life\"</td>\n",
       "      <td>\"save\"</td>\n",
       "      <td>\"best\"</td>\n",
       "      <td>\"side\"</td>\n",
       "      <td>\"excellent\"</td>\n",
       "      <td>Baby Delivery Doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"patient\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"time\"</td>\n",
       "      <td>\"care\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"n't\"</td>\n",
       "      <td>\"like\"</td>\n",
       "      <td>\"take\"</td>\n",
       "      <td>\"know\"</td>\n",
       "      <td>Great Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"office\"</td>\n",
       "      <td>\"wait\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"staff\"</td>\n",
       "      <td>\"time\"</td>\n",
       "      <td>\"n't\"</td>\n",
       "      <td>\"get\"</td>\n",
       "      <td>\"rude\"</td>\n",
       "      <td>\"appointment\"</td>\n",
       "      <td>\"see\"</td>\n",
       "      <td>Long Wait Time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1            2          3            4        5  \\\n",
       "0      \"dr.\"    \"staff\"       \"care\"   \"doctor\"  \"recommend\"  \"great\"   \n",
       "1  \"surgery\"      \"dr.\"  \"procedure\"  \"surgeon\"     \"result\"  \"would\"   \n",
       "2   \"manner\"  \"bedside\"     \"doctor\"     \"good\"      \"great\"   \"life\"   \n",
       "3   \"doctor\"  \"patient\"        \"dr.\"     \"time\"       \"care\"     \"'s\"   \n",
       "4   \"office\"     \"wait\"     \"doctor\"    \"staff\"       \"time\"    \"n't\"   \n",
       "\n",
       "             6                7              8            9  \\\n",
       "0      \"would\"  \"knowledgeable\"       \"highly\"    \"patient\"   \n",
       "1  \"recommend\"        \"perform\"           \"go\"     \"breast\"   \n",
       "2       \"save\"           \"best\"         \"side\"  \"excellent\"   \n",
       "3        \"n't\"           \"like\"         \"take\"       \"know\"   \n",
       "4        \"get\"           \"rude\"  \"appointment\"        \"see\"   \n",
       "\n",
       "                  topic  \n",
       "0        Bad Experience  \n",
       "1             High Cost  \n",
       "2  Baby Delivery Doctor  \n",
       "3          Great Review  \n",
       "4        Long Wait Time  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_22 = pd.DataFrame([re.findall(\"\\\"\\w*[.']?\\w*\\\"\", x[1]) for x in tops[5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_22['topic'] = ['Neutral Visit', 'Attentive Doctors', 'Got Surgery', 'Common Visit', 'Good Doctor for All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"child\"</td>\n",
       "      <td>\"u\"</td>\n",
       "      <td>\"son\"</td>\n",
       "      <td>\"make\"</td>\n",
       "      <td>\"daughter\"</td>\n",
       "      <td>\"baby\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"feel\"</td>\n",
       "      <td>\"love\"</td>\n",
       "      <td>Neutral Visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"pain\"</td>\n",
       "      <td>\"surgery\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"year\"</td>\n",
       "      <td>\"back\"</td>\n",
       "      <td>\"life\"</td>\n",
       "      <td>\"dr\"</td>\n",
       "      <td>\"knee\"</td>\n",
       "      <td>\"month\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>Attentive Doctors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"call\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"patient\"</td>\n",
       "      <td>\"medical\"</td>\n",
       "      <td>\"test\"</td>\n",
       "      <td>\"insurance\"</td>\n",
       "      <td>\"result\"</td>\n",
       "      <td>\"office\"</td>\n",
       "      <td>\"get\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>Got Surgery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"question\"</td>\n",
       "      <td>\"answer\"</td>\n",
       "      <td>\"time\"</td>\n",
       "      <td>\"ask\"</td>\n",
       "      <td>\"take\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"rush\"</td>\n",
       "      <td>\"make\"</td>\n",
       "      <td>\"concern\"</td>\n",
       "      <td>\"appointment\"</td>\n",
       "      <td>Common Visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"n't\"</td>\n",
       "      <td>\"go\"</td>\n",
       "      <td>\"tell\"</td>\n",
       "      <td>\"say\"</td>\n",
       "      <td>\"get\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"see\"</td>\n",
       "      <td>\"could\"</td>\n",
       "      <td>\"ask\"</td>\n",
       "      <td>Good Doctor for All</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3       4            5         6  \\\n",
       "0       \"dr.\"    \"child\"        \"u\"      \"son\"  \"make\"   \"daughter\"    \"baby\"   \n",
       "1      \"pain\"  \"surgery\"      \"dr.\"     \"year\"  \"back\"       \"life\"      \"dr\"   \n",
       "2      \"call\"      \"dr.\"  \"patient\"  \"medical\"  \"test\"  \"insurance\"  \"result\"   \n",
       "3  \"question\"   \"answer\"     \"time\"      \"ask\"  \"take\"        \"dr.\"    \"rush\"   \n",
       "4       \"n't\"       \"go\"     \"tell\"      \"say\"   \"get\"      \"would\"  \"doctor\"   \n",
       "\n",
       "          7          8              9                topic  \n",
       "0      \"'s\"     \"feel\"         \"love\"        Neutral Visit  \n",
       "1    \"knee\"    \"month\"        \"would\"    Attentive Doctors  \n",
       "2  \"office\"      \"get\"       \"doctor\"          Got Surgery  \n",
       "3    \"make\"  \"concern\"  \"appointment\"         Common Visit  \n",
       "4     \"see\"    \"could\"          \"ask\"  Good Doctor for All  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Topic 6 and 8 are hard to label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem#3:\n",
    "Compare your program’s output with and without lemmatization. Which of these settings generates better topics? Is lemmatization worth doing? (compare the goodness of the topics with and without lemmatization). Explain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lemmatized documents generated better topics. Each topic has a common thread and different topics are quite divergent from each other. Thus, it is worth it to lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines(\"\\nTask 2 Problem 1: Topics without lemmatization\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_21_ori.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')\n",
    "tbl_22_ori.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines('All of the topics without lemmatization looks confusing.\\n')\n",
    "    f.writelines(\"\\nTask 2 Problem 2: Topics with lemmatization\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_21.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')\n",
    "tbl_22.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines(\"Only topic 6 and 8 are hard to label.\\n\")\n",
    "    f.writelines(\"\\nTask 2 Problem 3\\n\")\n",
    "    f.writelines(\"Lemmatized documents generated better topics. Each topic has a common thread and different topics are quite divergent from each other. Thus, it is worth it to lemmatize.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra-credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem#1: [10 points]\n",
    "Repeat Task#2 but this time with k = 20 topics.\n",
    "What do you notice? Are the results with 20 topics better than those with 10 topics (under both with and without lemmatization scenarios)? Again, ‘better results’ here refers to the goodness of your topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA model needs many iterations/passes and a large corpus to work well\n",
    "# must define the number of topics you want to extract from the corpus\n",
    "ldamodel_2 = LdaModel(corpus, num_topics=20, id2word = Dic, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA model needs many iterations/passes and a large corpus to work well\n",
    "# must define the number of topics you want to extract from the corpus\n",
    "ori_ldamodel_2 = LdaModel(ori_corpus, num_topics=20, id2word = ori_Dic, passes=20, iterations=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  - Without lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print out the top 10 words in each topic\n",
    "ori_tops_2 = ori_ldamodel_2.print_topics(num_topics=20, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_ec1_ori = pd.DataFrame([re.findall(\"\\\"\\w*[.']?\\w*\\\"\", x[1]) for x in ori_tops_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"point\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"cheap\"</td>\n",
       "      <td>\"home\"</td>\n",
       "      <td>\"individual\"</td>\n",
       "      <td>\"feel\"</td>\n",
       "      <td>\"immensely\"</td>\n",
       "      <td>\"seeing\"</td>\n",
       "      <td>\"pa\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"pulling\"</td>\n",
       "      <td>\"physican\"</td>\n",
       "      <td>\"bonakdar\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"baldwin\"</td>\n",
       "      <td>\"everytime\"</td>\n",
       "      <td>\"manager\"</td>\n",
       "      <td>\"emch\"</td>\n",
       "      <td>\"hr\"</td>\n",
       "      <td>\"refreshing\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"associates\"</td>\n",
       "      <td>\"jensen\"</td>\n",
       "      <td>\"customer\"</td>\n",
       "      <td>\"bigger\"</td>\n",
       "      <td>\"diligent\"</td>\n",
       "      <td>\"everyone\"</td>\n",
       "      <td>\"kent\"</td>\n",
       "      <td>\"laughing\"</td>\n",
       "      <td>\"hr\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"nami\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"baldwin\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"figured\"</td>\n",
       "      <td>\"anal\"</td>\n",
       "      <td>\"discovered\"</td>\n",
       "      <td>\"loewe\"</td>\n",
       "      <td>\"bothered\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"pulmonary\"</td>\n",
       "      <td>\"ford\"</td>\n",
       "      <td>\"mian\"</td>\n",
       "      <td>\"home\"</td>\n",
       "      <td>\"nasri\"</td>\n",
       "      <td>\"realized\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"easier\"</td>\n",
       "      <td>\"completed\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"lazy\"</td>\n",
       "      <td>\"becoming\"</td>\n",
       "      <td>\"copies\"</td>\n",
       "      <td>\"several\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"panchal\"</td>\n",
       "      <td>\"ready\"</td>\n",
       "      <td>\"mexico\"</td>\n",
       "      <td>\"amazingly\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"glazer\"</td>\n",
       "      <td>\"laptop\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"loewe\"</td>\n",
       "      <td>\"bothered\"</td>\n",
       "      <td>\"individual\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"looked\"</td>\n",
       "      <td>\"iron\"</td>\n",
       "      <td>\"past\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"docs\"</td>\n",
       "      <td>\"assist\"</td>\n",
       "      <td>\"decent\"</td>\n",
       "      <td>\"recommending\"</td>\n",
       "      <td>\"disc\"</td>\n",
       "      <td>\"reply\"</td>\n",
       "      <td>\"corrective\"</td>\n",
       "      <td>\"determined\"</td>\n",
       "      <td>\"calming\"</td>\n",
       "      <td>\"fractured\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"drink\"</td>\n",
       "      <td>\"redo\"</td>\n",
       "      <td>\"alcohol\"</td>\n",
       "      <td>\"precious\"</td>\n",
       "      <td>\"honor\"</td>\n",
       "      <td>\"caution\"</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>\"ignored\"</td>\n",
       "      <td>\"humiliated\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"operations\"</td>\n",
       "      <td>\"precious\"</td>\n",
       "      <td>\"dipatri\"</td>\n",
       "      <td>\"kent\"</td>\n",
       "      <td>\"series\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"laptop\"</td>\n",
       "      <td>\"endocrinologist\"</td>\n",
       "      <td>\"everyone\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"complaint\"</td>\n",
       "      <td>\"associated\"</td>\n",
       "      <td>\"medicine\"</td>\n",
       "      <td>\"easier\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"medicines\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"closely\"</td>\n",
       "      <td>\"favorite\"</td>\n",
       "      <td>\"bye\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"imagine\"</td>\n",
       "      <td>\"awar\"</td>\n",
       "      <td>\"period\"</td>\n",
       "      <td>\"advocate\"</td>\n",
       "      <td>\"avoid\"</td>\n",
       "      <td>\"rather\"</td>\n",
       "      <td>\"exam\"</td>\n",
       "      <td>\"lopez\"</td>\n",
       "      <td>\"shots\"</td>\n",
       "      <td>\"hated\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"pulmonary\"</td>\n",
       "      <td>\"likely\"</td>\n",
       "      <td>\"associates\"</td>\n",
       "      <td>\"pulling\"</td>\n",
       "      <td>\"reasons\"</td>\n",
       "      <td>\"loses\"</td>\n",
       "      <td>\"closely\"</td>\n",
       "      <td>\"bar\"</td>\n",
       "      <td>\"pretend\"</td>\n",
       "      <td>\"service\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"jensen\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"honor\"</td>\n",
       "      <td>\"harwer\"</td>\n",
       "      <td>\"redo\"</td>\n",
       "      <td>\"ethics\"</td>\n",
       "      <td>\"'m\"</td>\n",
       "      <td>\"closely\"</td>\n",
       "      <td>\"service\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"blown\"</td>\n",
       "      <td>\"laptop\"</td>\n",
       "      <td>\"ethics\"</td>\n",
       "      <td>\"madoff\"</td>\n",
       "      <td>\"associates\"</td>\n",
       "      <td>\"kent\"</td>\n",
       "      <td>\"completed\"</td>\n",
       "      <td>\"precious\"</td>\n",
       "      <td>\"service\"</td>\n",
       "      <td>\"asset\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"redo\"</td>\n",
       "      <td>\"sarcastic\"</td>\n",
       "      <td>\"anterior\"</td>\n",
       "      <td>\"oncology\"</td>\n",
       "      <td>\"paralyzed\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"laptop\"</td>\n",
       "      <td>\"howell\"</td>\n",
       "      <td>\"ethics\"</td>\n",
       "      <td>\"flexible\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"precious\"</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"feeling\"</td>\n",
       "      <td>\"cut\"</td>\n",
       "      <td>\"laptop\"</td>\n",
       "      <td>\"exam\"</td>\n",
       "      <td>\"ended\"</td>\n",
       "      <td>\"hateful\"</td>\n",
       "      <td>\"kidding\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"dascombe\"</td>\n",
       "      <td>\"consistent\"</td>\n",
       "      <td>\"miracle\"</td>\n",
       "      <td>\"option\"</td>\n",
       "      <td>\"keeping\"</td>\n",
       "      <td>\"humiliated\"</td>\n",
       "      <td>\"deals\"</td>\n",
       "      <td>\"hills\"</td>\n",
       "      <td>\"interesting\"</td>\n",
       "      <td>\"ethical\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"data\"</td>\n",
       "      <td>\"hart\"</td>\n",
       "      <td>\"j.\"</td>\n",
       "      <td>\"likely\"</td>\n",
       "      <td>\"seizure\"</td>\n",
       "      <td>\"repeated\"</td>\n",
       "      <td>\"relaxed\"</td>\n",
       "      <td>\"recommendations\"</td>\n",
       "      <td>\"associates\"</td>\n",
       "      <td>\"beware\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"bye\"</td>\n",
       "      <td>\"illegal\"</td>\n",
       "      <td>\"partner\"</td>\n",
       "      <td>\"school\"</td>\n",
       "      <td>\"knowing\"</td>\n",
       "      <td>\"food\"</td>\n",
       "      <td>\"p.a\"</td>\n",
       "      <td>\"holistic\"</td>\n",
       "      <td>\"flu\"</td>\n",
       "      <td>\"dealt\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2               3             4  \\\n",
       "0        \"data\"       \"point\"          \"'s\"         \"cheap\"        \"home\"   \n",
       "1     \"pulling\"    \"physican\"    \"bonakdar\"          \"data\"     \"baldwin\"   \n",
       "2     \"service\"  \"associates\"      \"jensen\"      \"customer\"      \"bigger\"   \n",
       "3        \"data\"        \"nami\"         \"cut\"       \"baldwin\"     \"service\"   \n",
       "4        \"data\"   \"pulmonary\"        \"ford\"          \"mian\"        \"home\"   \n",
       "5        \"lazy\"    \"becoming\"      \"copies\"       \"several\"        \"data\"   \n",
       "6      \"glazer\"      \"laptop\"         \"cut\"         \"loewe\"    \"bothered\"   \n",
       "7        \"docs\"      \"assist\"      \"decent\"  \"recommending\"        \"disc\"   \n",
       "8        \"data\"       \"drink\"        \"redo\"       \"alcohol\"    \"precious\"   \n",
       "9         \"cut\"  \"operations\"    \"precious\"       \"dipatri\"        \"kent\"   \n",
       "10  \"complaint\"  \"associated\"    \"medicine\"        \"easier\"        \"data\"   \n",
       "11    \"imagine\"        \"awar\"      \"period\"      \"advocate\"       \"avoid\"   \n",
       "12  \"pulmonary\"      \"likely\"  \"associates\"       \"pulling\"     \"reasons\"   \n",
       "13     \"jensen\"          \"'s\"         \"cut\"         \"honor\"      \"harwer\"   \n",
       "14      \"blown\"      \"laptop\"      \"ethics\"        \"madoff\"  \"associates\"   \n",
       "15       \"redo\"   \"sarcastic\"    \"anterior\"      \"oncology\"   \"paralyzed\"   \n",
       "16   \"precious\"    \"expected\"        \"data\"       \"feeling\"         \"cut\"   \n",
       "17   \"dascombe\"  \"consistent\"     \"miracle\"        \"option\"     \"keeping\"   \n",
       "18       \"data\"        \"hart\"          \"j.\"        \"likely\"     \"seizure\"   \n",
       "19        \"bye\"     \"illegal\"     \"partner\"        \"school\"     \"knowing\"   \n",
       "\n",
       "               5             6                  7                  8  \\\n",
       "0   \"individual\"        \"feel\"        \"immensely\"           \"seeing\"   \n",
       "1    \"everytime\"     \"manager\"             \"emch\"               \"hr\"   \n",
       "2     \"diligent\"    \"everyone\"             \"kent\"         \"laughing\"   \n",
       "3      \"figured\"        \"anal\"       \"discovered\"            \"loewe\"   \n",
       "4        \"nasri\"    \"realized\"          \"service\"           \"easier\"   \n",
       "5          \"cut\"     \"panchal\"            \"ready\"           \"mexico\"   \n",
       "6   \"individual\"     \"service\"           \"looked\"             \"iron\"   \n",
       "7        \"reply\"  \"corrective\"       \"determined\"          \"calming\"   \n",
       "8        \"honor\"     \"caution\"         \"expected\"          \"ignored\"   \n",
       "9       \"series\"     \"service\"           \"laptop\"  \"endocrinologist\"   \n",
       "10   \"medicines\"     \"service\"          \"closely\"         \"favorite\"   \n",
       "11      \"rather\"        \"exam\"            \"lopez\"            \"shots\"   \n",
       "12       \"loses\"     \"closely\"              \"bar\"          \"pretend\"   \n",
       "13        \"redo\"      \"ethics\"               \"'m\"          \"closely\"   \n",
       "14        \"kent\"   \"completed\"         \"precious\"          \"service\"   \n",
       "15         \"cut\"      \"laptop\"           \"howell\"           \"ethics\"   \n",
       "16      \"laptop\"        \"exam\"            \"ended\"          \"hateful\"   \n",
       "17  \"humiliated\"       \"deals\"            \"hills\"      \"interesting\"   \n",
       "18    \"repeated\"     \"relaxed\"  \"recommendations\"       \"associates\"   \n",
       "19        \"food\"         \"p.a\"         \"holistic\"              \"flu\"   \n",
       "\n",
       "               9  \n",
       "0           \"pa\"  \n",
       "1   \"refreshing\"  \n",
       "2           \"hr\"  \n",
       "3     \"bothered\"  \n",
       "4    \"completed\"  \n",
       "5    \"amazingly\"  \n",
       "6         \"past\"  \n",
       "7    \"fractured\"  \n",
       "8   \"humiliated\"  \n",
       "9     \"everyone\"  \n",
       "10         \"bye\"  \n",
       "11       \"hated\"  \n",
       "12     \"service\"  \n",
       "13     \"service\"  \n",
       "14       \"asset\"  \n",
       "15    \"flexible\"  \n",
       "16     \"kidding\"  \n",
       "17     \"ethical\"  \n",
       "18      \"beware\"  \n",
       "19       \"dealt\"  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_ec1_ori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All of the topics without lemmatization looks confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   - With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print out the top 10 words in each topic\n",
    "tops_2 = ldamodel_2.print_topics(num_topics=20, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_ec2 = pd.DataFrame([re.findall(\"\\\"\\w*[.']?\\w*\\\"\", x[1]) for x in tops_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"call\"</td>\n",
       "      <td>\"rude\"</td>\n",
       "      <td>\"staff\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"office\"</td>\n",
       "      <td>\"never\"</td>\n",
       "      <td>\"worst\"</td>\n",
       "      <td>\"return\"</td>\n",
       "      <td>\"ever\"</td>\n",
       "      <td>\"phone\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"surgery\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"surgeon\"</td>\n",
       "      <td>\"recommend\"</td>\n",
       "      <td>\"perform\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>\"dr\"</td>\n",
       "      <td>\"result\"</td>\n",
       "      <td>\"highly\"</td>\n",
       "      <td>\"knee\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"tell\"</td>\n",
       "      <td>\"go\"</td>\n",
       "      <td>\"get\"</td>\n",
       "      <td>\"say\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"office\"</td>\n",
       "      <td>\"call\"</td>\n",
       "      <td>\"n't\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>\"see\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"family\"</td>\n",
       "      <td>\"friend\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"recommend\"</td>\n",
       "      <td>\"schwartz\"</td>\n",
       "      <td>\"member\"</td>\n",
       "      <td>\"refer\"</td>\n",
       "      <td>\"satisfy\"</td>\n",
       "      <td>\"rat\"</td>\n",
       "      <td>\"many\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"husband\"</td>\n",
       "      <td>\"cancer\"</td>\n",
       "      <td>\"mother\"</td>\n",
       "      <td>\"hospital\"</td>\n",
       "      <td>\"life\"</td>\n",
       "      <td>\"day\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"implant\"</td>\n",
       "      <td>\"teeth\"</td>\n",
       "      <td>\"u\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"best\"</td>\n",
       "      <td>\"dr\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>\"recommend\"</td>\n",
       "      <td>\"ever\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"care\"</td>\n",
       "      <td>\"life\"</td>\n",
       "      <td>\"anyone\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"n't\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"go\"</td>\n",
       "      <td>\"say\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"know\"</td>\n",
       "      <td>\"want\"</td>\n",
       "      <td>\"like\"</td>\n",
       "      <td>\"get\"</td>\n",
       "      <td>\"could\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"pain\"</td>\n",
       "      <td>\"back\"</td>\n",
       "      <td>\"problem\"</td>\n",
       "      <td>\"help\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"foot\"</td>\n",
       "      <td>\"year\"</td>\n",
       "      <td>\"month\"</td>\n",
       "      <td>\"get\"</td>\n",
       "      <td>\"severe\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"care\"</td>\n",
       "      <td>\"patient\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"physician\"</td>\n",
       "      <td>\"excellent\"</td>\n",
       "      <td>\"best\"</td>\n",
       "      <td>\"knowledgeable\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"medical\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"surgery\"</td>\n",
       "      <td>\"procedure\"</td>\n",
       "      <td>\"go\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"breast\"</td>\n",
       "      <td>\"would\"</td>\n",
       "      <td>\"result\"</td>\n",
       "      <td>\"look\"</td>\n",
       "      <td>\"dentist\"</td>\n",
       "      <td>\"do\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"question\"</td>\n",
       "      <td>\"time\"</td>\n",
       "      <td>\"answer\"</td>\n",
       "      <td>\"take\"</td>\n",
       "      <td>\"concern\"</td>\n",
       "      <td>\"listen\"</td>\n",
       "      <td>\"explain\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"patient\"</td>\n",
       "      <td>\"ask\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"son\"</td>\n",
       "      <td>\"u\"</td>\n",
       "      <td>\"dr\"</td>\n",
       "      <td>\"side\"</td>\n",
       "      <td>\"blood\"</td>\n",
       "      <td>\"weight\"</td>\n",
       "      <td>\"bed\"</td>\n",
       "      <td>\"brown\"</td>\n",
       "      <td>\"old\"</td>\n",
       "      <td>\"brain\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"wait\"</td>\n",
       "      <td>\"time\"</td>\n",
       "      <td>\"appointment\"</td>\n",
       "      <td>\"office\"</td>\n",
       "      <td>\"staff\"</td>\n",
       "      <td>\"hour\"</td>\n",
       "      <td>\"see\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"minute\"</td>\n",
       "      <td>\"get\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"wife\"</td>\n",
       "      <td>\"treatment\"</td>\n",
       "      <td>\"skin\"</td>\n",
       "      <td>\"clinic\"</td>\n",
       "      <td>\"dermatologist\"</td>\n",
       "      <td>\"offer\"</td>\n",
       "      <td>\"diagnosis\"</td>\n",
       "      <td>\"cure\"</td>\n",
       "      <td>\"cancer\"</td>\n",
       "      <td>\"unnecessary\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"test\"</td>\n",
       "      <td>\"problem\"</td>\n",
       "      <td>\"symptom\"</td>\n",
       "      <td>\"diagnose\"</td>\n",
       "      <td>\"prescribe\"</td>\n",
       "      <td>\"cause\"</td>\n",
       "      <td>\"infection\"</td>\n",
       "      <td>\"ear\"</td>\n",
       "      <td>\"thyroid\"</td>\n",
       "      <td>\"antibiotic\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"year\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"see\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"find\"</td>\n",
       "      <td>\"'ve\"</td>\n",
       "      <td>\"go\"</td>\n",
       "      <td>\"practice\"</td>\n",
       "      <td>\"many\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"like\"</td>\n",
       "      <td>\"feel\"</td>\n",
       "      <td>\"time\"</td>\n",
       "      <td>\"make\"</td>\n",
       "      <td>\"take\"</td>\n",
       "      <td>\"really\"</td>\n",
       "      <td>\"care\"</td>\n",
       "      <td>\"patient\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"listen\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"staff\"</td>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"helpful\"</td>\n",
       "      <td>\"great\"</td>\n",
       "      <td>\"office\"</td>\n",
       "      <td>\"friendly\"</td>\n",
       "      <td>\"recommend\"</td>\n",
       "      <td>\"make\"</td>\n",
       "      <td>\"feel\"</td>\n",
       "      <td>\"always\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"dr.\"</td>\n",
       "      <td>\"child\"</td>\n",
       "      <td>\"daughter\"</td>\n",
       "      <td>\"baby\"</td>\n",
       "      <td>\"deliver\"</td>\n",
       "      <td>\"pregnancy\"</td>\n",
       "      <td>\"first\"</td>\n",
       "      <td>\"make\"</td>\n",
       "      <td>\"'s\"</td>\n",
       "      <td>\"u\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"manner\"</td>\n",
       "      <td>\"bedside\"</td>\n",
       "      <td>\"good\"</td>\n",
       "      <td>\"great\"</td>\n",
       "      <td>\"doctor\"</td>\n",
       "      <td>\"excellent\"</td>\n",
       "      <td>\"father\"</td>\n",
       "      <td>\"recommend\"</td>\n",
       "      <td>\"definitely\"</td>\n",
       "      <td>\"ob\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1              2            3                4  \\\n",
       "0       \"call\"       \"rude\"        \"staff\"     \"doctor\"         \"office\"   \n",
       "1    \"surgery\"        \"dr.\"      \"surgeon\"  \"recommend\"        \"perform\"   \n",
       "2       \"tell\"         \"go\"          \"get\"        \"say\"         \"doctor\"   \n",
       "3     \"family\"     \"friend\"          \"dr.\"  \"recommend\"       \"schwartz\"   \n",
       "4    \"husband\"     \"cancer\"       \"mother\"   \"hospital\"           \"life\"   \n",
       "5     \"doctor\"       \"best\"           \"dr\"      \"would\"      \"recommend\"   \n",
       "6        \"n't\"         \"'s\"           \"go\"        \"say\"         \"doctor\"   \n",
       "7       \"pain\"       \"back\"      \"problem\"       \"help\"            \"dr.\"   \n",
       "8       \"care\"    \"patient\"          \"dr.\"     \"doctor\"      \"physician\"   \n",
       "9    \"surgery\"  \"procedure\"           \"go\"        \"dr.\"         \"breast\"   \n",
       "10  \"question\"       \"time\"       \"answer\"       \"take\"        \"concern\"   \n",
       "11       \"son\"          \"u\"           \"dr\"       \"side\"          \"blood\"   \n",
       "12      \"wait\"       \"time\"  \"appointment\"     \"office\"          \"staff\"   \n",
       "13      \"wife\"  \"treatment\"         \"skin\"     \"clinic\"  \"dermatologist\"   \n",
       "14      \"test\"    \"problem\"      \"symptom\"   \"diagnose\"      \"prescribe\"   \n",
       "15      \"year\"        \"dr.\"          \"see\"     \"doctor\"             \"'s\"   \n",
       "16      \"like\"       \"feel\"         \"time\"       \"make\"           \"take\"   \n",
       "17     \"staff\"        \"dr.\"      \"helpful\"      \"great\"         \"office\"   \n",
       "18       \"dr.\"      \"child\"     \"daughter\"       \"baby\"        \"deliver\"   \n",
       "19    \"manner\"    \"bedside\"         \"good\"      \"great\"         \"doctor\"   \n",
       "\n",
       "              5            6                7             8              9  \n",
       "0       \"never\"      \"worst\"         \"return\"        \"ever\"        \"phone\"  \n",
       "1       \"would\"         \"dr\"         \"result\"      \"highly\"         \"knee\"  \n",
       "2      \"office\"       \"call\"            \"n't\"       \"would\"          \"see\"  \n",
       "3      \"member\"      \"refer\"        \"satisfy\"         \"rat\"         \"many\"  \n",
       "4         \"day\"         \"'s\"        \"implant\"       \"teeth\"            \"u\"  \n",
       "5        \"ever\"        \"dr.\"           \"care\"        \"life\"       \"anyone\"  \n",
       "6        \"know\"       \"want\"           \"like\"         \"get\"        \"could\"  \n",
       "7        \"foot\"       \"year\"          \"month\"         \"get\"       \"severe\"  \n",
       "8   \"excellent\"       \"best\"  \"knowledgeable\"          \"'s\"      \"medical\"  \n",
       "9       \"would\"     \"result\"           \"look\"     \"dentist\"           \"do\"  \n",
       "10     \"listen\"    \"explain\"            \"dr.\"     \"patient\"          \"ask\"  \n",
       "11     \"weight\"        \"bed\"          \"brown\"         \"old\"        \"brain\"  \n",
       "12       \"hour\"        \"see\"         \"doctor\"      \"minute\"          \"get\"  \n",
       "13      \"offer\"  \"diagnosis\"           \"cure\"      \"cancer\"  \"unnecessary\"  \n",
       "14      \"cause\"  \"infection\"            \"ear\"     \"thyroid\"   \"antibiotic\"  \n",
       "15       \"find\"        \"'ve\"             \"go\"    \"practice\"         \"many\"  \n",
       "16     \"really\"       \"care\"        \"patient\"      \"doctor\"       \"listen\"  \n",
       "17   \"friendly\"  \"recommend\"           \"make\"        \"feel\"       \"always\"  \n",
       "18  \"pregnancy\"      \"first\"           \"make\"          \"'s\"            \"u\"  \n",
       "19  \"excellent\"     \"father\"      \"recommend\"  \"definitely\"           \"ob\"  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_ec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> With more topics, there are still topics that are hard to label, like topic 6. Moreover, there are topics (e.g. Topic 3 and Topic 17) that seem to be overlapping and hard to differentiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines(\"\\nExtra Credit\\n\\nTopics without lemmatization:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_ec1_ori.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines('All of the topics without lemmatization looks confusing.\\n')\n",
    "    f.writelines(\"\\nTopics with lemmatization:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbl_ec2.to_csv(r'analysis.txt', index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('analysis.txt', 'a') as f:\n",
    "    f.writelines(\"With more topics, there are still topics that are hard to label, like topic 6. Moreover, there are topics (e.g. Topic 3 and Topic 17) that seem to be overlapping and hard to differentiate.\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
