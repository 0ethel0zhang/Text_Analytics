{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string, re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from compressed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = tarfile.open(\"review_polarity.tar.gz\", \"r\")\n",
    "train_pos_file_list = []\n",
    "train_neg_file_list = []\n",
    "test_pos_file_list = []\n",
    "test_neg_file_list = []\n",
    "for member in f.getmembers():\n",
    "    file=f.extractfile(member)\n",
    "    content=file.read()\n",
    "    if 'pos' in member.get_info()['name']:\n",
    "        if 'cv9' in member.get_info()['name']:\n",
    "            test_pos_file_list.append(content)\n",
    "        else:\n",
    "            train_pos_file_list.append(content)\n",
    "    else:\n",
    "        if 'cv9' in member.get_info()['name']:\n",
    "            test_neg_file_list.append(content)\n",
    "        else:\n",
    "            train_neg_file_list.append(content)\n",
    "    #sys.exit()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_labels = [1 for i in range(len(train_pos_file_list))]\n",
    "train_neg_labels = [0 for i in range(len(train_neg_file_list))]\n",
    "\n",
    "test_pos_labels = [1 for i in range(len(test_pos_file_list))]\n",
    "test_neg_labels = [0 for i in range(len(test_neg_file_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_pos_labels + train_neg_labels\n",
    "test_labels = test_pos_labels + test_neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_file_list = [str(text).replace(\"b'\", \"\").replace(\"\\\\n\",\"\").replace(\"\\\\'\",\"'\") for text in train_pos_file_list]\n",
    "train_neg_file_list = [str(text).replace(\"b'\", \"\").replace(\"\\\\n\",\"\").replace(\"\\\\'\",\"'\") for text in train_neg_file_list]\n",
    "test_pos_file_list = [str(text).replace(\"b'\", \"\").replace(\"\\\\n\",\"\").replace(\"\\\\'\",\"'\") for text in test_pos_file_list]\n",
    "test_neg_file_list = [str(text).replace(\"b'\", \"\").replace(\"\\\\n\",\"\").replace(\"\\\\'\",\"'\") for text in test_neg_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file_list = train_pos_file_list + train_neg_file_list\n",
    "test_file_list = test_pos_file_list + test_neg_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, classifier, n=10):\n",
    "    lines = []\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()  \n",
    "    topn_pos_class = sorted(zip(classifier.feature_log_prob_[1], feature_names),reverse=True)[:n]\n",
    "    topn_neg_class = sorted(zip(classifier.feature_log_prob_[0], feature_names),reverse=True)[:n]    \n",
    "\n",
    "    print(\"Important words in positive reviews\")\n",
    "    for coef, feature in topn_pos_class:\n",
    "        lines.append([class_labels[1], coef, feature])\n",
    "        print(class_labels[1], coef, feature) \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in negative reviews\")\n",
    "    for coef, feature in topn_neg_class:\n",
    "        lines.append([class_labels[0], coef, feature])\n",
    "        print(class_labels[0], coef, feature)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_Accuracy(whichcleaning, binary=False, ngram=False, tfidf=False, show=True, stem=False):\n",
    "    files_train = [whichcleaning(word_tokenize(x), stem) for x in train_file_list]\n",
    "    files_test = [whichcleaning(word_tokenize(x), stem) for x in test_file_list]\n",
    "\n",
    "    if binary:\n",
    "        vectorizer = CountVectorizer(binary=True)\n",
    "    elif ngram:\n",
    "        vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "    elif tfidf:\n",
    "        vectorizer = TfidfVectorizer(min_df = 5, stop_words='english', sublinear_tf=True, max_df = round(len(train_file_list) * .8))\n",
    "    else:\n",
    "        vectorizer = CountVectorizer()\n",
    "\n",
    "    train_features = vectorizer.fit_transform([doc for doc in files_train])\n",
    "    test_features = vectorizer.transform([doc for doc in files_test])\n",
    "\n",
    "    tokens = vectorizer.get_feature_names()\n",
    "\n",
    "    nb_clf = MultinomialNB()\n",
    "\n",
    "    nb_clf.fit(train_features, train_labels)\n",
    "    predictions = nb_clf.predict(test_features)\n",
    "\n",
    "    accuracy = accuracy_score(predictions, test_labels)\n",
    "    print(\"Accuracy is {}%\".format(accuracy*100))\n",
    "    \n",
    "    if show:\n",
    "        # print out most informative features\n",
    "        thing = show_most_informative_features(vectorizer, nb_clf, n=5)\n",
    "        return accuracy, thing\n",
    "    else:\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\tProblem 1. \n",
    "In building the baselines, what shallow text features make sense for the task as a first-stab approach? (e.g., a language modeling approach is a standard way to tackle this problem, i.e., a bag-of-words approach). Experiment with the following baseline models (note that you have to run a POS tagger for models M3):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the classifier for each baseline feature and report the performance. What is the best model and which model is the least performant? \n",
    "\n",
    "- How do you interpret the differences in performance across these models (i.e., why do you think one model is better than another)? \n",
    "\n",
    "- For the unigram models M1-M4, list the top 5 most informative words identified by the classifier. What do you notice here? (compare these lists)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -M1: word present/absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word present/absent\n",
    "def clean(tokenized, stem=False):\n",
    "    punctuation_free = [x for x in tokenized if not re.fullmatch('[' + string.punctuation + ']+', x)]\n",
    "    unique_punctuation_free = list(set(punctuation_free))\n",
    "    if stem:\n",
    "        stemmedWords = []\n",
    "        for word in unique_punctuation_free:\n",
    "            try:\n",
    "                a = stemmer.stem(word)\n",
    "                stemmedWords.append(a)\n",
    "            except:\n",
    "                next\n",
    "        return ' '.join(stemmedWords)\n",
    "    else:\n",
    "        return ' '.join(unique_punctuation_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create a dataframe from a word matrix\n",
    "def wm2df(wm, feat_names):\n",
    "    # create an index for each row\n",
    "    doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(wm)]\n",
    "    df = pd.DataFrame(data=wm.toarray(), index=doc_names,\n",
    "                   columns=feat_names)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 86.0%\n",
      "Important words in positive reviews\n",
      "1 -5.956848974266556 the\n",
      "1 -5.956848974266556 of\n",
      "1 -5.957959468550583 to\n",
      "1 -5.957959468550583 is\n",
      "1 -5.957959468550583 and\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -5.889864371418765 the\n",
      "0 -5.889864371418765 of\n",
      "0 -5.889864371418765 and\n",
      "0 -5.890974865702792 to\n",
      "0 -5.890974865702792 is\n"
     ]
    }
   ],
   "source": [
    "accuracy_wp, imp_wp = Get_Accuracy(whichcleaning=clean, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'w+') as f:\n",
    "    f.writelines(\"\\nProblem 1: M1 Word absence & presence\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(accuracy_wp))\n",
    "    for line in imp_wp:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))\n",
    "    f.writelines(\"The accuracy is quite high. However, the most informative words are almost exactly the same for both classes. These words seems to be stop words, that are common is any documents.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The accuracy is quite high. However, the most informative words are almost exactly the same for both classes. These words seems to be stop words, that are common is any documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - M2: term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# term frequency\n",
    "def clean1(tokenized, stem=False):\n",
    "    punctuation_free = [x for x in tokenized if not re.fullmatch('[' + string.punctuation + ']+', x)]\n",
    "    if stem:\n",
    "        stemmedWords = []\n",
    "        for word in punctuation_free:\n",
    "            try:\n",
    "                a = stemmer.stem(word)\n",
    "                stemmedWords.append(a)\n",
    "            except:\n",
    "                next\n",
    "        return ' '.join(stemmedWords)\n",
    "    else:\n",
    "        return ' '.join(punctuation_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 83.5%\n",
      "Important words in positive reviews\n",
      "1 -2.840738587277439 the\n",
      "1 -3.5756175119023332 and\n",
      "1 -3.6397703179736975 of\n",
      "1 -3.759997481071675 to\n",
      "1 -3.898152823893758 is\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -2.899320163163642 the\n",
      "0 -3.7056424046697813 and\n",
      "0 -3.719386357592498 of\n",
      "0 -3.7196026127744553 to\n",
      "0 -4.0058678632326075 is\n"
     ]
    }
   ],
   "source": [
    "accuracy_tf, imp_tf = Get_Accuracy(whichcleaning=clean1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 1: M2 Term frequency\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(accuracy_tf))\n",
    "    for line in imp_tf:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))\n",
    "    f.writelines(\"The accuracy is also quite high. However, once again, the most informative words are almost exactly the same for both classes. These words seems to be stop words, that are common is any documents.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The accuracy is also quite high. However, once again, the most informative words are almost exactly the same for both classes. These words seems to be stop words, that are common is any documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - M3: POS advj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_pos(tokenized, stem=False):\n",
    "    punctuation_free = [x for x in tokenized if not re.fullmatch('[' + string.punctuation + ']+', x)]\n",
    "    word_posTags = pos_tag(punctuation_free)\n",
    "    # get adjv words by the POS tags\n",
    "    adjv_words = [x[0] for x in word_posTags if len(re.findall('(RB\\w*|JJ\\w*)', x[1]))>0]\n",
    "    # presence/absence\n",
    "    unique_adjv_words = list(set(adjv_words))\n",
    "    if stem:\n",
    "        stemmedWords = []\n",
    "        for word in unique_adjv_words:\n",
    "            try:\n",
    "                a = stemmer.stem(word)\n",
    "                stemmedWords.append(a)\n",
    "            except:\n",
    "                next\n",
    "        return ' '.join(stemmedWords)\n",
    "    else:\n",
    "        return ' '.join(unique_adjv_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 87.0%\n",
      "Important words in positive reviews\n",
      "1 -4.839375545880551 not\n",
      "1 -4.978294782472198 more\n",
      "1 -5.005486790167449 when\n",
      "1 -5.065441651637363 so\n",
      "1 -5.122313162591969 most\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -4.784832166746287 not\n",
      "0 -4.916657559525709 when\n",
      "0 -4.930387752337611 so\n",
      "0 -4.930387752337611 more\n",
      "0 -4.979177916507043 only\n"
     ]
    }
   ],
   "source": [
    "accuracy_pos, imp_pos = Get_Accuracy(whichcleaning=clean_pos, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 1: M3 Adj/Adv POS tagging\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(accuracy_pos))\n",
    "    for line in imp_pos:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))\n",
    "    f.writelines(\"The accuracy is the highest so far. However, once again, the most informative words are almost exactly the same for both classes. These words seems to be stop words, that are common is any documents.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The accuracy is the highest so far. However, once again, the most informative words are almost exactly the same for both classes. These words seems to be stop words, that are common is any documents."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -M4: Sublinear tf-idf\n",
    "Note: For model M4 use sublinear tf-idf. Here, besides removing stop words, you also have to remove those vocabulary words that occurred in less than 5 documents (i.e., files) and those that occurred in more than 80% of documents.![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tfidf(tokenized, stem=False):\n",
    "    cleaned = [x for x in tokenized if not re.fullmatch('[' + string.punctuation + ']+', x) and x not in stop_words]\n",
    "    if stem:\n",
    "        stemmedWords = []\n",
    "        for word in cleaned:\n",
    "            try:\n",
    "                a = stemmer.stem(word)\n",
    "                stemmedWords.append(a)\n",
    "            except:\n",
    "                next\n",
    "        return ' '.join(stemmedWords)\n",
    "    else:\n",
    "        return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 85.5%\n",
      "Important words in positive reviews\n",
      "1 -6.950690881656748 movie\n",
      "1 -7.117846360899243 like\n",
      "1 -7.217263992577482 story\n",
      "1 -7.219986250430932 life\n",
      "1 -7.229668354616171 good\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -6.738589295181579 movie\n",
      "0 -6.97872693412327 like\n",
      "0 -7.098268371686496 bad\n",
      "0 -7.183224842908503 good\n",
      "0 -7.211225327985219 plot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "accuracy_tfidf, imp_tfidf = Get_Accuracy(whichcleaning=clean_tfidf, tfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 1: M4 Sublinear TF-IDF\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(accuracy_tfidf))\n",
    "    for line in imp_tfidf:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))\n",
    "    f.writelines(\"The accuracy is also quite high. However, once again, the most informative words are almost exactly the same for both classes, even when the stop words are removed. The only noticeable difference is that the negative word 'bad' is only most informative for the negative class.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The accuracy is also quite high. However, once again, the most informative words are almost exactly the same for both classes, even when the stop words are removed. The only noticeable difference is that the negative word 'bad' is only most informative for the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -M5: Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 83.5%\n"
     ]
    }
   ],
   "source": [
    "accuracy_bg = Get_Accuracy(clean1, ngram=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 1: M5 Bigrams\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(accuracy_bg))\n",
    "    f.writelines(\"Bigram accuracy is the lowest among all. Seems like neigbouring words do not help the classifier to identify classes.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bigram accuracy is the lowest among all. Seems like neigbouring words do not help the classifier to identify classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. \n",
    "Redo Problem1 but with stemming (use Porter’s stemmer). Is this worth doing? Compare the models’ performance with those at Problem1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 86.5%\n",
      "Important words in positive reviews\n",
      "1 -5.874126057465444 the\n",
      "1 -5.874126057465444 of\n",
      "1 -5.875236551749471 to\n",
      "1 -5.875236551749471 is\n",
      "1 -5.875236551749471 and\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -5.811011388055521 the\n",
      "0 -5.811011388055521 of\n",
      "0 -5.811011388055521 and\n",
      "0 -5.8121218823395475 to\n",
      "0 -5.8121218823395475 is\n"
     ]
    }
   ],
   "source": [
    "acc_p2m1, imp_p2m1 = Get_Accuracy(whichcleaning=clean, binary=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 2: M1\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(acc_p2m1))\n",
    "    for line in imp_p2m1:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 83.5%\n",
      "Important words in positive reviews\n",
      "1 -2.8218423300926645 the\n",
      "1 -3.5565865292205547 and\n",
      "1 -3.6204997425983514 of\n",
      "1 -3.7408313906412616 to\n",
      "1 -3.879199411704203 is\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -2.878436116876138 the\n",
      "0 -3.6844726304885285 and\n",
      "0 -3.6981445087418567 of\n",
      "0 -3.6984328385932024 to\n",
      "0 -3.984986093661419 is\n"
     ]
    }
   ],
   "source": [
    "acc_p2m2, imp_p2m2 = Get_Accuracy(whichcleaning=clean1, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 2: M2\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(acc_p2m2))\n",
    "    for line in imp_p2m2:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 86.5%\n",
      "Important words in positive reviews\n",
      "1 -4.816078359324657 not\n",
      "1 -4.954997595916304 more\n",
      "1 -4.982189603611555 when\n",
      "1 -5.042144465081469 so\n",
      "1 -5.099015976036076 most\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -4.7584993363994705 not\n",
      "0 -4.892977250628024 when\n",
      "0 -4.9067074434399265 so\n",
      "0 -4.9067074434399265 more\n",
      "0 -4.955497607609358 onli\n"
     ]
    }
   ],
   "source": [
    "acc_p2m3, imp_p2m3 = Get_Accuracy(whichcleaning=clean_pos, binary=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 2: M3\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(acc_p2m3))\n",
    "    for line in imp_p2m3:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 85.0%\n",
      "Important words in positive reviews\n",
      "1 -6.851678248100096 charact\n",
      "1 -6.873881312329068 like\n",
      "1 -6.913031948970374 make\n",
      "1 -6.93374621915882 time\n",
      "1 -6.975088959919418 stori\n",
      "-----------------------------------------\n",
      "Important words in negative reviews\n",
      "0 -6.725568462109111 like\n",
      "0 -6.811139260741474 charact\n",
      "0 -6.881642269038005 bad\n",
      "0 -6.890574116575978 make\n",
      "0 -6.939384912776044 time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "acc_p2m4, imp_p2m4 = Get_Accuracy(whichcleaning=clean_tfidf, tfidf=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 2: M4\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(acc_p2m4))\n",
    "    for line in imp_p2m4:\n",
    "        f.writelines(\"{} {} {}\\n\".format(line[0], line[1], line[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 83.5%\n"
     ]
    }
   ],
   "source": [
    "acc_p2m5 = Get_Accuracy(clean1, ngram=True, show=False, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 2: M5\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(acc_p2m5))\n",
    "    f.writelines(\"The accuracy did not significantly increase and sometimes decreased so it is not worth stemming.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The accuracy did not significantly increase and sometimes decreased so it is not worth stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. \n",
    "Here you have to experiment with the Pos/Neg ratio (use the EmoLex lexicon provided). Compare the performance of this model with those you got for Problems 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emolex = []\n",
    "with open(\"NRC_Emotion.txt\", \"r\") as f:\n",
    "    emolex.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emolex = [x.replace(\"\\n\",\"\").split(\"\\t\") for x in emolex[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emolex_df = pd.DataFrame(emolex).rename(columns=dict(zip(range(4), [\"word\",'area','pos_neg','none'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only take the mode for words with multiple sentiments\n",
    "pos_neg = emolex_df.groupby(\"word\").pos_neg.apply(lambda x: x.mode().mean()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_dic = dict(zip(pos_neg.word, pos_neg.pos_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_score(tokenized):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for word in tokenized:\n",
    "        try:\n",
    "            score = pos_neg_dic[word]\n",
    "            if score == 1:\n",
    "                neg += 1\n",
    "            elif score == 0:\n",
    "                pos += 1\n",
    "        except:\n",
    "            next\n",
    "    if neg == 0 and pos == 0:\n",
    "        return 0\n",
    "    elif neg == 0:\n",
    "        return pos\n",
    "    else:\n",
    "        return pos/neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_train = [sentiment_score(word_tokenize(x)) for x in train_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = [sentiment_score(word_tokenize(x)) for x in test_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 50.0%\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "\n",
    "nb_clf.fit(np.reshape(scores_train, (len(scores_train), 1)), train_labels)\n",
    "\n",
    "predictions = nb_clf.predict(np.reshape(scores, (len(scores), 1)))\n",
    "\n",
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "print(\"Accuracy is {}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 3: Pos/Neg Ratio\\n\")\n",
    "    f.writelines(\"Accuracy is {}%\\n\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4. \n",
    "How would you improve over the models you have experimented with so far? Meaning, what text features are most beneficial to the task of sentiment analysis? -- i.e., if you had to do it again, what would you change? For example, if you had to solve the problem in a different (and hopefully more efficient way), which features would you choose? Write 1-2 short paragraphs about the features you might want to try for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numbers to placeholders\n",
    "# get rid of stopwords / movie related words\n",
    "# only keeping the words that are not neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on the previous exercise, it seems like it would be beneficial to do the following things:\n",
    "    1. Numbers can be converted to just placeholders. There are many numbers that became parts of the dictionary. However, the different numbers do not have different sentiments attached unless they are used as ways to rate things.\n",
    "    2. Removing stop words and words that are generic for the subject (e.g. movie, story, plot). As is seen previously, removing stop words helped with model performance. We can go one step further to remove generic words that refers to the subject in discussion. Previously, the informative words were things like movie, story, and plot. However, they are just words that are synonyms to the subject \"movie\". Thus getting rid of them might make the more sentiment-telling words surface more easily.\n",
    "    3. Only keeping words that are not neutral (i.e. sentiment-telling words). Even though the pos/neg ratio did not work too well with predicting sentiment, one thing that it can be useful is as a filter. After only keeping the non-neutral words, if will be more clear what the sentiment of the text is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answers.txt', 'a') as f:\n",
    "    f.writelines(\"\\nProblem 4: Improvements\\n\")\n",
    "    f.writelines(\"1. Numbers can be converted to just placeholders. There are many numbers that became parts of the dictionary. However, the different numbers do not have different sentiments attached unless they are used as ways to rate things.\\n\")\n",
    "    f.writelines(\"2. Removing stop words and words that are generic for the subject (e.g. movie, story, plot). As is seen previously, removing stop words helped with model performance. We can go one step further to remove generic words that refers to the subject in discussion. Previously, the informative words were things like movie, story, and plot. However, they are just words that are synonyms to the subject 'movie'. Thus getting rid of them might make the more sentiment-telling words surface more easily.\\n\")\n",
    "    f.writelines(\"3. Only keeping words that are not neutral (i.e. sentiment-telling words). Even though the pos/neg ratio did not work too well with predicting sentiment, one thing that it can be useful is as a filter. After only keeping the non-neutral words, if will be more clear what the sentiment of the text is.\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
